{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0f9920-ce66-430c-aeb5-cadc1dbf1ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sam3d-objects/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.10.0 initialized:\n",
      "   CUDA Toolkit 12.8, Driver 12.9\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA A40\" (44 GiB, sm_86, mempool enabled)\n",
      "   Kernel cache:\n",
      "     /root/.cache/warp/1.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-23 21:47:35.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36mset_attention_backend\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mGPU name is NVIDIA A40\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-23 21:47:38.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.tdfy_dit.modules.sparse\u001b[0m:\u001b[36m__from_env\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m[SPARSE] Backend: spconv, Attention: sdpa\u001b[0m\n",
      "\u001b[32m2025-11-23 21:47:42.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.tdfy_dit.modules.attention\u001b[0m:\u001b[36m__from_env\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1m[ATTENTION] Using backend: sdpa\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPARSE][CONV] spconv algo: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-23 21:47:43.145\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n",
      "\u001b[32m2025-11-23 21:47:43.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n",
      "\u001b[32m2025-11-23 21:47:43.239\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n",
      "/root/miniconda3/envs/sam3d-objects/lib/python3.11/site-packages/moge/model/v1.py:171: UserWarning: The following deprecated/invalid arguments are ignored: {'output_mask': True, 'split_head': True}\n",
      "  warnings.warn(f\"The following deprecated/invalid arguments are ignored: {deprecated_kwargs}\")\n",
      "\u001b[32m2025-11-23 21:47:57.809\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n",
      "\u001b[32m2025-11-23 21:47:57.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mself.device: cuda\u001b[0m\n",
      "\u001b[32m2025-11-23 21:47:57.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mCUDA_VISIBLE_DEVICES: None\u001b[0m\n",
      "\u001b[32m2025-11-23 21:47:57.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mActually using GPU: 0\u001b[0m\n",
      "\u001b[32m2025-11-23 21:47:57.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36minit_pose_decoder\u001b[0m:\u001b[36m295\u001b[0m - \u001b[1mUsing pose decoder: ScaleShiftInvariant\u001b[0m\n",
      "\u001b[32m2025-11-23 21:47:57.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mLoading model weights...\u001b[0m\n",
      "\u001b[32m2025-11-23 21:47:58.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from checkpoints/hf/ss_generator.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:05.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from checkpoints/hf/slat_generator.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:09.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from checkpoints/hf/ss_decoder.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:09.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from checkpoints/hf/slat_decoder_gs.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:09.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from checkpoints/hf/slat_decoder_gs_4.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:10.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from checkpoints/hf/slat_decoder_mesh.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:10.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoading DINO model: dinov2_vitl14_reg from facebookresearch/dinov2 (source: github)\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:11.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mLoaded DINO model - type: <class 'dinov2.models.vision_transformer.DinoVisionTransformer'>, embed_dim: 1024, patch_size: (14, 14)\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:11.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoading DINO model: dinov2_vitl14_reg from facebookresearch/dinov2 (source: github)\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:12.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mLoaded DINO model - type: <class 'dinov2.models.vision_transformer.DinoVisionTransformer'>, embed_dim: 1024, patch_size: (14, 14)\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:12.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from checkpoints/hf/ss_generator.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:15.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoading DINO model: dinov2_vitl14_reg from facebookresearch/dinov2 (source: github)\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:15.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mLoaded DINO model - type: <class 'dinov2.models.vision_transformer.DinoVisionTransformer'>, embed_dim: 1024, patch_size: (14, 14)\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:15.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoading DINO model: dinov2_vitl14_reg from facebookresearch/dinov2 (source: github)\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:16.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.dit.embedder.dino\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mLoaded DINO model - type: <class 'dinov2.models.vision_transformer.DinoVisionTransformer'>, embed_dim: 1024, patch_size: (14, 14)\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:16.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.io\u001b[0m:\u001b[36mload_model_from_checkpoint\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoading checkpoint from checkpoints/hf/slat_generator.ckpt\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:18.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36moverride_ss_generator_cfg_config\u001b[0m:\u001b[36m436\u001b[0m - \u001b[1mss_generator parameters: inference_steps=25, cfg_strength=7, cfg_interval=[0, 500], rescale_t=3, cfg_strength_pm=0.0\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:18.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36moverride_slat_generator_cfg_config\u001b[0m:\u001b[36m458\u001b[0m - \u001b[1mslat_generator parameters: inference_steps=25, cfg_strength=1, cfg_interval=[0, 500], rescale_t=1\u001b[0m\n",
      "\u001b[32m2025-11-23 21:48:18.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mLoading model weights completed!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "os.environ[\"CONDA_PREFIX\"] = sys.prefix\n",
    "# import inference code\n",
    "sys.path.append(\"notebook\")\n",
    "from inference import Inference, load_image, load_single_mask\n",
    "\n",
    "# load model\n",
    "tag = \"hf\"\n",
    "config_path = f\"checkpoints/{tag}/pipeline.yaml\"\n",
    "inference = Inference(config_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ed4f59-68c3-41f1-af7f-31d1df859b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-23 21:49:10.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36msample_sparse_structure\u001b[0m:\u001b[36m662\u001b[0m - \u001b[1mSampling sparse structure: inference_steps=25, strength=7, interval=[0, 500], rescale_t=3, cfg_strength_pm=0.0\u001b[0m\n",
      "\u001b[32m2025-11-23 21:49:10.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36mget_condition_input\u001b[0m:\u001b[36m631\u001b[0m - \u001b[1mRunning condition embedder ...\u001b[0m\n",
      "\u001b[32m2025-11-23 21:49:10.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36mget_condition_input\u001b[0m:\u001b[36m635\u001b[0m - \u001b[1mCondition embedder finishes!\u001b[0m\n",
      "\u001b[32m2025-11-23 21:49:17.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36msample_sparse_structure\u001b[0m:\u001b[36m712\u001b[0m - \u001b[1mDownsampled coords from 26895 to 26338\u001b[0m\n",
      "\u001b[32m2025-11-23 21:49:17.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline_pointmap\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m368\u001b[0m - \u001b[1mRescaling scale by 1 after downsampling\u001b[0m\n",
      "\u001b[32m2025-11-23 21:49:17.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36msample_slat\u001b[0m:\u001b[36m742\u001b[0m - \u001b[1mSampling sparse latent: inference_steps=25, strength=1, interval=[0, 500], rescale_t=1\u001b[0m\n",
      "\u001b[32m2025-11-23 21:49:17.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36mget_condition_input\u001b[0m:\u001b[36m631\u001b[0m - \u001b[1mRunning condition embedder ...\u001b[0m\n",
      "\u001b[32m2025-11-23 21:49:17.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36mget_condition_input\u001b[0m:\u001b[36m635\u001b[0m - \u001b[1mCondition embedder finishes!\u001b[0m\n",
      "\u001b[32m2025-11-23 21:49:34.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36mdecode_slat\u001b[0m:\u001b[36m604\u001b[0m - \u001b[1mDecoding sparse latent...\u001b[0m\n",
      "\u001b[32m2025-11-23 21:50:02.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36mpostprocess_slat_output\u001b[0m:\u001b[36m538\u001b[0m - \u001b[1mPostprocessing mesh with option with_mesh_postprocess False, with_texture_baking False...\u001b[0m\n",
      "\u001b[32m2025-11-23 21:50:02.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline_pointmap\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m416\u001b[0m - \u001b[1mFinished!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load image and mask\n",
    "image = load_image(\"notebook/images/shutterstock_stylish_kidsroom_1640806567/image.png\")\n",
    "mask = load_single_mask(\"notebook/images/shutterstock_stylish_kidsroom_1640806567\", index=14)\n",
    "\n",
    "# run model\n",
    "output = inference(image, mask, seed=42)\n",
    "\n",
    "# export gaussian splat\n",
    "output[\"gs\"].save_ply(f\"splat.ply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6345b8e0-ae6d-4e50-ad57-279399d499fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "mesh = output[\"glb\"] # trimesh object\n",
    "mesh.export(\"my_mesh.ply\")\n",
    "clear_output(wait=True)\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Sam Env",
   "language": "python",
   "name": "sam3d-objects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
